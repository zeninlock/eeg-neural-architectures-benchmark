{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppose your cleaned data is in the variable 'preprocessed_data'\n",
    "eeg_data_cleaned = np.load('eeg_data_cleaned.npy')\n",
    "y = np.load('y.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isha Chaudhari\\python\\tf_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "eeg_data_cleaned, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now split the remaining data into training (70%) and validation (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7739,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7739, 61, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (11057, 61, 256)\n",
      "Augmented: (7739, 61, 256)\n",
      "Mixup: (7739, 61, 256)\n",
      "Combined: (23217, 61, 256)\n",
      "Labels: (23217,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 3D EEG Augmentation Functions ---\n",
    "\n",
    "def add_gaussian_noise(X, noise_level=0.02):\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "def random_time_shift(X, max_shift=8):\n",
    "    shifted = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        shift = np.random.randint(-max_shift, max_shift)\n",
    "        if shift > 0:\n",
    "            shifted[i, :, shift:] = X[i, :, :-shift]\n",
    "        elif shift < 0:\n",
    "            shifted[i, :, :shift] = X[i, :, -shift:]\n",
    "        else:\n",
    "            shifted[i] = X[i]\n",
    "    return shifted\n",
    "\n",
    "def random_amplitude_scaling(X, scale_range=(0.95, 1.05)):\n",
    "    # X shape: (samples, channels, timepoints, 1)\n",
    "    scales = np.random.uniform(scale_range[0], scale_range[1], (X.shape[0], 1, 1))\n",
    "    return X * scales\n",
    "\n",
    "def channel_reflection(X):\n",
    "    # Reflect channels (reverse channel order)\n",
    "    return X[:, ::-1, :]\n",
    "\n",
    "def channel_masking(X, mask_prob=0.1):\n",
    "    X_masked = X.copy()\n",
    "    for i in range(X.shape[0]):\n",
    "        for ch in range(X.shape[1]):\n",
    "            if np.random.rand() < mask_prob:\n",
    "                X_masked[i, ch, :] = 0\n",
    "    return X_masked\n",
    "\n",
    "def signal_flipping(X):\n",
    "    # Reverse time axis\n",
    "    return X[:, :, ::-1]\n",
    "\n",
    "def mixup(X, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = X.shape[0]\n",
    "    index = np.random.permutation(batch_size)\n",
    "    X_mix = lam * X + (1 - lam) * X[index]\n",
    "    y_mix = lam * y + (1 - lam) * y[index]\n",
    "    return X_mix, y_mix\n",
    "\n",
    "# --- Apply Augmentations ---\n",
    "\n",
    "# Apply augmentations sequentially\n",
    "# Assume you already split your data:\n",
    "# X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Apply augmentations to X_train only\n",
    "X_aug = add_gaussian_noise(X_train)\n",
    "X_aug = random_time_shift(X_aug)\n",
    "X_aug = random_amplitude_scaling(X_aug)\n",
    "X_aug = channel_reflection(X_aug)\n",
    "X_aug = channel_masking(X_aug)\n",
    "X_aug = signal_flipping(X_aug)\n",
    "\n",
    "# Mixup (on training set only)\n",
    "X_mix, y_mix = mixup(X_train, y_train, alpha=0.2)\n",
    "\n",
    "# Combine all data\n",
    "X_train_combined = np.concatenate([X_train, X_aug, X_mix], axis=0)\n",
    "y_train_combined = np.concatenate([y_train, y_train, y_mix], axis=0)\n",
    "\n",
    "\n",
    "print(\"Original:\", eeg_data_cleaned.shape)\n",
    "print(\"Augmented:\", X_aug.shape)\n",
    "print(\"Mixup:\", X_mix.shape)\n",
    "print(\"Combined:\", X_train_combined.shape)\n",
    "print(\"Labels:\", y_train_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # For training, validation, and test sets\n",
    "# X_train_combined = np.transpose(X_train_combined, (0, 2, 1))  # (samples, 256, 61)\n",
    "# X_val = np.transpose(X_val, (0, 2, 1))\n",
    "# X_test = np.transpose(X_test, (0, 2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23217, 61, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = (61, 256, 1)  # (channels, timepoints, 1)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),  # Dropout after pooling\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),  # Increased dropout for deeper layers\n",
    "\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),  # Batch norm before dense\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 61, 256, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 61, 256, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 128, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 128, 32)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 128, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 128, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 64, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 15, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 32, 128)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 32, 256)        295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 7, 32, 256)       1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 16, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 16, 256)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12288)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3145984   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,537,025\n",
      "Trainable params: 3,535,553\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # You can also use 'val_accuracy'\n",
    "    patience=7,                 # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True   # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_combined = np.array(X_train_combined, dtype=np.float32)\n",
    "y_train_combined = np.array(y_train_combined, dtype=np.float32)  # or int32 for classification\n",
    "X_val = np.array(X_val, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23217, 61, 256)\n",
      "(23217,)\n",
      "(1659, 61, 256)\n",
      "(1659,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_combined.shape)\n",
    "print(y_train_combined.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "726/726 [==============================] - 47s 52ms/step - loss: 0.6505 - accuracy: 0.5925 - val_loss: 0.5636 - val_accuracy: 0.7324\n",
      "Epoch 2/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.5452 - accuracy: 0.6459 - val_loss: 0.4942 - val_accuracy: 0.7553\n",
      "Epoch 3/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.5005 - accuracy: 0.6740 - val_loss: 0.4562 - val_accuracy: 0.7703\n",
      "Epoch 4/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.4675 - accuracy: 0.6919 - val_loss: 4.1555 - val_accuracy: 0.7697\n",
      "Epoch 5/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.4481 - accuracy: 0.7062 - val_loss: 0.3183 - val_accuracy: 0.8722\n",
      "Epoch 6/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.4128 - accuracy: 0.7276 - val_loss: 0.2868 - val_accuracy: 0.8861\n",
      "Epoch 7/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.3872 - accuracy: 0.7405 - val_loss: 0.2655 - val_accuracy: 0.8933\n",
      "Epoch 8/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.3617 - accuracy: 0.7555 - val_loss: 0.2237 - val_accuracy: 0.9168\n",
      "Epoch 9/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.3416 - accuracy: 0.7664 - val_loss: 0.3109 - val_accuracy: 0.8987\n",
      "Epoch 10/50\n",
      "726/726 [==============================] - 39s 53ms/step - loss: 0.3293 - accuracy: 0.7736 - val_loss: 0.2236 - val_accuracy: 0.9156\n",
      "Epoch 11/50\n",
      "726/726 [==============================] - 38s 53ms/step - loss: 0.3087 - accuracy: 0.7834 - val_loss: 0.2076 - val_accuracy: 0.9313\n",
      "Epoch 12/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2982 - accuracy: 0.7894 - val_loss: 0.2168 - val_accuracy: 0.9132\n",
      "Epoch 13/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2864 - accuracy: 0.7939 - val_loss: 0.1831 - val_accuracy: 0.9373\n",
      "Epoch 14/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2758 - accuracy: 0.7991 - val_loss: 0.1908 - val_accuracy: 0.9355\n",
      "Epoch 15/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2658 - accuracy: 0.8023 - val_loss: 0.1891 - val_accuracy: 0.9403\n",
      "Epoch 16/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2565 - accuracy: 0.8078 - val_loss: 0.1807 - val_accuracy: 0.9391\n",
      "Epoch 17/50\n",
      "726/726 [==============================] - 41s 56ms/step - loss: 0.2544 - accuracy: 0.8084 - val_loss: 0.1541 - val_accuracy: 0.9530\n",
      "Epoch 18/50\n",
      "726/726 [==============================] - 43s 59ms/step - loss: 0.2470 - accuracy: 0.8114 - val_loss: 0.1769 - val_accuracy: 0.9397\n",
      "Epoch 19/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2415 - accuracy: 0.8135 - val_loss: 0.1965 - val_accuracy: 0.9385\n",
      "Epoch 20/50\n",
      "726/726 [==============================] - 42s 57ms/step - loss: 0.2345 - accuracy: 0.8154 - val_loss: 0.1615 - val_accuracy: 0.9445\n",
      "Epoch 21/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2365 - accuracy: 0.8150 - val_loss: 0.1538 - val_accuracy: 0.9476\n",
      "Epoch 22/50\n",
      "726/726 [==============================] - 42s 57ms/step - loss: 0.2318 - accuracy: 0.8161 - val_loss: 0.1475 - val_accuracy: 0.9458\n",
      "Epoch 23/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2308 - accuracy: 0.8171 - val_loss: 0.1428 - val_accuracy: 0.9548\n",
      "Epoch 24/50\n",
      "726/726 [==============================] - 43s 59ms/step - loss: 0.2228 - accuracy: 0.8218 - val_loss: 0.2021 - val_accuracy: 0.9228\n",
      "Epoch 25/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2313 - accuracy: 0.8159 - val_loss: 0.1341 - val_accuracy: 0.9608\n",
      "Epoch 26/50\n",
      "726/726 [==============================] - 42s 57ms/step - loss: 0.2173 - accuracy: 0.8232 - val_loss: 0.1481 - val_accuracy: 0.9524\n",
      "Epoch 27/50\n",
      "726/726 [==============================] - 42s 57ms/step - loss: 0.2141 - accuracy: 0.8245 - val_loss: 0.1308 - val_accuracy: 0.9590\n",
      "Epoch 28/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2118 - accuracy: 0.8240 - val_loss: 0.1440 - val_accuracy: 0.9530\n",
      "Epoch 29/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2113 - accuracy: 0.8259 - val_loss: 0.1701 - val_accuracy: 0.9482\n",
      "Epoch 30/50\n",
      "726/726 [==============================] - 42s 58ms/step - loss: 0.2070 - accuracy: 0.8269 - val_loss: 0.1363 - val_accuracy: 0.9560\n",
      "Epoch 31/50\n",
      "726/726 [==============================] - 42s 57ms/step - loss: 0.2059 - accuracy: 0.8265 - val_loss: 0.1305 - val_accuracy: 0.9578\n",
      "Epoch 32/50\n",
      "726/726 [==============================] - 43s 59ms/step - loss: 0.2028 - accuracy: 0.8276 - val_loss: 0.1133 - val_accuracy: 0.9668\n",
      "Epoch 33/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2059 - accuracy: 0.8259 - val_loss: 0.1211 - val_accuracy: 0.9590\n",
      "Epoch 34/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.1979 - accuracy: 0.8299 - val_loss: 0.1337 - val_accuracy: 0.9578\n",
      "Epoch 35/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.2024 - accuracy: 0.8277 - val_loss: 0.1245 - val_accuracy: 0.9572\n",
      "Epoch 36/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.1939 - accuracy: 0.8315 - val_loss: 0.1245 - val_accuracy: 0.9566\n",
      "Epoch 37/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.1977 - accuracy: 0.8293 - val_loss: 0.1195 - val_accuracy: 0.9620\n",
      "Epoch 38/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.1956 - accuracy: 0.8310 - val_loss: 0.1234 - val_accuracy: 0.9656\n",
      "Epoch 39/50\n",
      "726/726 [==============================] - 38s 52ms/step - loss: 0.1952 - accuracy: 0.8296 - val_loss: 0.1192 - val_accuracy: 0.9614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_combined, y_train_combined,\n",
    "    epochs=50,                \n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.1165 - accuracy: 0.9596\n",
      "Test accuracy: 0.9596\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 9ms/step\n",
      "[[ 566   38]\n",
      " [  29 1026]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       604\n",
      "           1       0.96      0.97      0.97      1055\n",
      "\n",
      "    accuracy                           0.96      1659\n",
      "   macro avg       0.96      0.95      0.96      1659\n",
      "weighted avg       0.96      0.96      0.96      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_eeg_cnn_model_with_preprocessing_augmentation.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
