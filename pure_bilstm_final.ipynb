{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8199262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_built_with_cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532dac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import CubicSpline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfd7199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8845, 256, 61)\n",
      "Val: (1106, 256, 61)\n",
      "Test: (1106, 256, 61)\n"
     ]
    }
   ],
   "source": [
    "eeg_data = np.load('eeg_data_cleaned.npy')\n",
    "\n",
    "# Reshape for LSTM (samples, timesteps, features)\n",
    "X = np.transpose(eeg_data, (0, 2, 1))  # New shape: (11057, 256, 61)\n",
    "\n",
    "# Load labels (assuming y_labels exists)\n",
    "y = np.load('y.npy')\n",
    "\n",
    "\n",
    "# Step 1: Split off 10% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split remaining 90% into 80% train, 10% val\n",
    "train_ratio = 8 / 9  # 80% out of the remaining 90%\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=(1 - train_ratio), stratify=y_train_val, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c90157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "def add_noise(signal, noise_level=0.05):\n",
    "    noise = np.random.normal(0, noise_level, signal.shape)\n",
    "    return signal + noise\n",
    "\n",
    "def time_warp(signal, warp_factor=0.2):\n",
    "    orig_time = np.arange(signal.shape[0])\n",
    "    warp_points = np.random.uniform(-warp_factor, warp_factor, 2)\n",
    "    new_time = orig_time * (1 + warp_points[0]) + warp_points[1]\n",
    "    warped = np.zeros_like(signal)\n",
    "    for ch in range(signal.shape[1]):\n",
    "        cs = CubicSpline(orig_time, signal[:, ch])\n",
    "        warped[:, ch] = cs(new_time)\n",
    "    return warped\n",
    "\n",
    "def random_scaling(signal, scale_range=(0.8, 1.2)):\n",
    "    scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    return signal * scale\n",
    "\n",
    "def temporal_shift(signal, max_shift=10):\n",
    "    shift = np.random.randint(-max_shift, max_shift)\n",
    "    return np.roll(signal, shift, axis=0)\n",
    "\n",
    "def window_slice(signal, window_ratio=0.8):\n",
    "    seq_len = signal.shape[0]\n",
    "    window_size = int(seq_len * window_ratio)\n",
    "    start = np.random.randint(0, seq_len - window_size)\n",
    "    window = signal[start:start+window_size, :]\n",
    "    sliced = np.zeros_like(signal)\n",
    "    for ch in range(signal.shape[1]):\n",
    "        sliced[:, ch] = np.interp(\n",
    "            np.linspace(0, 1, seq_len),\n",
    "            np.linspace(0, 1, window_size),\n",
    "            window[:, ch]\n",
    "        )\n",
    "    return sliced\n",
    "\n",
    "def frequency_augmentation(signal, max_shift=5):\n",
    "    augmented = np.zeros_like(signal)\n",
    "    for ch in range(signal.shape[1]):\n",
    "        fft = np.fft.rfft(signal[:, ch])\n",
    "        shift = np.random.randint(-max_shift, max_shift)\n",
    "        shifted_fft = np.roll(fft, shift)\n",
    "        augmented[:, ch] = np.fft.irfft(shifted_fft, n=signal.shape[0])\n",
    "    return augmented\n",
    "\n",
    "def augment_EEG(X_batch):\n",
    "    \"\"\"Apply all augmentations in sequence to a batch.\"\"\"\n",
    "    augmented = []\n",
    "    for x in X_batch:\n",
    "        x_aug = x.copy()\n",
    "        x_aug = add_noise(x_aug)\n",
    "        x_aug = time_warp(x_aug)\n",
    "        x_aug = random_scaling(x_aug)\n",
    "        x_aug = temporal_shift(x_aug)\n",
    "        x_aug = window_slice(x_aug)\n",
    "        x_aug = frequency_augmentation(x_aug)\n",
    "        augmented.append(x_aug)\n",
    "    return np.array(augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c836f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_dataset(X_original, y_original, num_augmentations=1):\n",
    "    \"\"\"\n",
    "    Returns augmented dataset with guaranteed alignment\n",
    "    :param num_augmentations: Number of augmented copies per sample\n",
    "    \"\"\"\n",
    "    X_augmented = [X_original]\n",
    "    y_augmented = [y_original]\n",
    "\n",
    "    for _ in range(num_augmentations):\n",
    "        augmented_X = augment_EEG(X_original)\n",
    "        X_augmented.append(augmented_X)\n",
    "        y_augmented.append(y_original)\n",
    "\n",
    "    X_combined = np.concatenate(X_augmented, axis=0)\n",
    "    y_combined = np.concatenate(y_augmented, axis=0)\n",
    "    return X_combined, y_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27479a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_alignment(X_original, X_augmented, y_original, y_augmented):\n",
    "    \"\"\"Verify X-y alignment after augmentation\"\"\"\n",
    "    assert np.allclose(X_original, X_augmented[:len(X_original)]), \"Original data corrupted!\"\n",
    "    assert np.array_equal(y_original, y_augmented[:len(y_original)]), \"Original labels corrupted!\"\n",
    "    num_copies = len(X_augmented) // len(X_original) - 1\n",
    "    for copy_idx in range(1, num_copies+1):\n",
    "        start = copy_idx * len(X_original)\n",
    "        end = (copy_idx+1) * len(X_original)\n",
    "        assert np.array_equal(y_augmented[start:end], y_original), f\"Copy {copy_idx} misaligned!\"\n",
    "    print(\"✅ All data aligned perfectly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8148058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (8845, 256, 61) → Augmented shape: (17690, 256, 61)\n",
      "✅ All data aligned perfectly!\n"
     ]
    }
   ],
   "source": [
    "# Example usage (replace with your actual data)\n",
    "# X_train shape: (samples, timesteps, channels)\n",
    "# y_train shape: (samples,)\n",
    "\n",
    "\n",
    "\n",
    "# Create augmented dataset (e.g., double the data)\n",
    "X_aug, y_aug = create_augmented_dataset(X_train, y_train, num_augmentations=1)\n",
    "print(f\"Original shape: {X_train.shape} → Augmented shape: {X_aug.shape}\")\n",
    "\n",
    "# Verify alignment\n",
    "verify_alignment(X_train, X_aug, y_train, y_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "407dfcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17690, 256, 61)\n",
      "(17690,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_aug.shape)  # Output: (11057, 256, 61)\n",
    "print(y_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f9f6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = (256, 61)  # Timesteps, features (channels)\n",
    "\n",
    "model_lstm_large_8255 = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    \n",
    "    # Bidirectional LSTM layers with residual connections\n",
    "    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Bidirectional(layers.LSTM(256)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Dense layers\n",
    "    layers.Dense(512, activation='elu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),\n",
    "    \n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm_smol = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='elu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc4419bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_83 (Bidirecti  (None, 256, 256)         194560    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_119 (Ba  (None, 256, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 256, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_84 (Bidirecti  (None, 128)              164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_120 (Ba  (None, 128)              512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_121 (Ba  (None, 64)               256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369,025\n",
      "Trainable params: 368,129\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define input shape (timesteps, features)\n",
    "input_shape = (256, 61)\n",
    "\n",
    "# Build the model\n",
    "model_lstm_very_regularized = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.GaussianNoise(0.1),\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            128,\n",
    "            return_sequences=True,\n",
    "            dropout=0.5,              # Input dropout\n",
    "            recurrent_dropout=0,      # Must be 0 for cuDNN acceleration\n",
    "            kernel_regularizer=regularizers.l2(1e-3)\n",
    "        )\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            64,\n",
    "            dropout=0.5,\n",
    "            recurrent_dropout=0,\n",
    "            kernel_regularizer=regularizers.l2(1e-3)\n",
    "        )\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(64, activation='elu', kernel_regularizer=regularizers.l2(1e-3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "input_shape = (256, 61)\n",
    "\n",
    "model_lstm = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            128,\n",
    "            return_sequences=True,\n",
    "            dropout=0.3,              # Reduced dropout\n",
    "            recurrent_dropout=0,      # cuDNN compatible\n",
    "            kernel_regularizer=regularizers.l2(1e-4)  # Reduced L2\n",
    "        )\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),             # Reduced dropout\n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            64,\n",
    "            dropout=0.3,              # Reduced dropout\n",
    "            recurrent_dropout=0,\n",
    "            kernel_regularizer=regularizers.l2(1e-4)  # Reduced L2\n",
    "        )\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),             # Reduced dropout\n",
    "    layers.Dense(64, activation='elu', kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.6),             # Reduced dropout\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.summary()\n",
    "# Compile the model\n",
    "model_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e31b907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "277/277 [==============================] - 28s 86ms/step - loss: 0.9604 - accuracy: 0.5462 - val_loss: 0.7251 - val_accuracy: 0.6293 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "277/277 [==============================] - 27s 99ms/step - loss: 0.8039 - accuracy: 0.5916 - val_loss: 0.7009 - val_accuracy: 0.6772 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "277/277 [==============================] - 27s 98ms/step - loss: 0.7428 - accuracy: 0.6256 - val_loss: 0.6800 - val_accuracy: 0.6926 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "277/277 [==============================] - 27s 97ms/step - loss: 0.7134 - accuracy: 0.6495 - val_loss: 0.6805 - val_accuracy: 0.6736 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "277/277 [==============================] - 27s 97ms/step - loss: 0.6755 - accuracy: 0.6836 - val_loss: 0.6307 - val_accuracy: 0.7297 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "277/277 [==============================] - 27s 99ms/step - loss: 0.6409 - accuracy: 0.7178 - val_loss: 0.7580 - val_accuracy: 0.6790 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "277/277 [==============================] - 28s 100ms/step - loss: 0.6531 - accuracy: 0.7068 - val_loss: 0.6103 - val_accuracy: 0.7414 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "277/277 [==============================] - 28s 101ms/step - loss: 0.6426 - accuracy: 0.7094 - val_loss: 0.7173 - val_accuracy: 0.6826 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "277/277 [==============================] - 28s 100ms/step - loss: 0.6383 - accuracy: 0.7238 - val_loss: 0.6133 - val_accuracy: 0.7450 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "277/277 [==============================] - 27s 99ms/step - loss: 0.6224 - accuracy: 0.7270 - val_loss: 0.6761 - val_accuracy: 0.6899 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "277/277 [==============================] - 27s 98ms/step - loss: 0.6279 - accuracy: 0.7304 - val_loss: 0.5983 - val_accuracy: 0.7586 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "277/277 [==============================] - 27s 96ms/step - loss: 0.5874 - accuracy: 0.7604 - val_loss: 0.5988 - val_accuracy: 0.7405 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "277/277 [==============================] - 27s 97ms/step - loss: 0.6053 - accuracy: 0.7489 - val_loss: 0.5774 - val_accuracy: 0.7658 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "277/277 [==============================] - 27s 99ms/step - loss: 0.5781 - accuracy: 0.7707 - val_loss: 0.5914 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "277/277 [==============================] - 28s 100ms/step - loss: 0.5519 - accuracy: 0.7873 - val_loss: 0.6408 - val_accuracy: 0.7351 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "277/277 [==============================] - 28s 99ms/step - loss: 0.5696 - accuracy: 0.7795 - val_loss: 0.6237 - val_accuracy: 0.7423 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "277/277 [==============================] - 28s 101ms/step - loss: 0.5548 - accuracy: 0.7847 - val_loss: 0.5635 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "277/277 [==============================] - 28s 100ms/step - loss: 0.5501 - accuracy: 0.7894 - val_loss: 0.6189 - val_accuracy: 0.7477 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "277/277 [==============================] - 27s 99ms/step - loss: 0.5676 - accuracy: 0.7835 - val_loss: 0.5762 - val_accuracy: 0.7731 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "277/277 [==============================] - 27s 98ms/step - loss: 0.5446 - accuracy: 0.7958 - val_loss: 0.7873 - val_accuracy: 0.6338 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "277/277 [==============================] - 27s 96ms/step - loss: 0.5372 - accuracy: 0.7968 - val_loss: 0.5906 - val_accuracy: 0.7812 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "277/277 [==============================] - 27s 98ms/step - loss: 0.5181 - accuracy: 0.8125 - val_loss: 0.5703 - val_accuracy: 0.7694 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Optional: Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Fit the model\n",
    "history = model_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d5fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 31ms/step - loss: 0.8378 - accuracy: 0.7161\n",
      "Test accuracy: 0.7161\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_lstm.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12bd99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save('eeg_pure_lstm_model1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78139f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
