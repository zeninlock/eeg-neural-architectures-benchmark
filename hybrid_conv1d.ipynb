{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# View 1st sample\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}, dtype: {X.dtype}\")\n",
    "print(f\"y shape: {y.shape}, dtype: {y.dtype}\\n\")\n",
    "\n",
    "# View 1st sample\n",
    "sample_index = 11050 # Change to 1, 2, etc., to view other samples\n",
    "print(f\"Sample {sample_index} EEG shape: {X[sample_index].shape}\")  # (64, 416)\n",
    "print(f\"Label for sample {sample_index}: {y[sample_index]}\\n\")\n",
    "\n",
    "# Print first 5 channels of the sample (each has 416 values)\n",
    "for i in range(64):  # 0 to 4\n",
    "    print(f\"Channel {i}:\")\n",
    "    print(X[sample_index][i])  # 1D array of 416 time points\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trim_trailing_zeros(data):\n",
    "    # data shape: (samples, channels, timepoints)\n",
    "    trimmed_data = []\n",
    "    for sample in data:\n",
    "        # Find timepoints where at least one channel is non-zero\n",
    "        mask = np.any(sample != 0, axis=0)\n",
    "        nonzero_indices = np.where(mask)[0]\n",
    "        \n",
    "        if len(nonzero_indices) == 0:\n",
    "            # Entire sample is zero; keep one zero timepoint to avoid empty arrays\n",
    "            trimmed_sample = sample[:, :1]\n",
    "        else:\n",
    "            last_valid_idx = nonzero_indices[-1] + 1\n",
    "            trimmed_sample = sample[:, :last_valid_idx]\n",
    "        \n",
    "        trimmed_data.append(trimmed_sample)\n",
    "    \n",
    "    return trimmed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_samples(trimmed_data, pad_to=None):\n",
    "    # pad_to: max length to pad to (if None, auto-detect)\n",
    "    n_samples = len(trimmed_data)\n",
    "    n_channels = trimmed_data[0].shape[0]\n",
    "    max_len = pad_to or max(s.shape[1] for s in trimmed_data)\n",
    "\n",
    "    padded = np.zeros((n_samples, n_channels, max_len))\n",
    "    for i, s in enumerate(trimmed_data):\n",
    "        padded[i, :, :s.shape[1]] = s\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = trim_trailing_zeros(data)\n",
    "padded_data = pad_samples(trimmed)  # Now ready for CNNs or ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clipped = np.clip(padded_data, -100, 100)  # values in microvolts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your data is in a NumPy array called eeg_data\n",
    "# eeg_data.shape == (11057, 64, 256)\n",
    "\n",
    "# Remove the last 3 channels (keep channels 0 to 60)\n",
    "eeg_data_cleaned = data_clipped[:, :61, :]\n",
    "\n",
    "# eeg_data_cleaned.shape will be (11057, 61, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11057, 61, 256)\n",
      "0\n",
      "-100.0 100.0 -1.0627293675958795 9.827144638860839\n",
      "y shape: (11057,), dtype: int64\n",
      "\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(eeg_data_cleaned.shape)  # should be (11053, 64, 416)\n",
    "print(np.isnan(eeg_data_cleaned).sum())  # check for NaNs\n",
    "print(np.min(eeg_data_cleaned), np.max(eeg_data_cleaned), np.mean(eeg_data_cleaned), np.std(eeg_data_cleaned))  # global stats\n",
    "\n",
    "print(f\"y shape: {y.shape}, dtype: {y.dtype}\\n\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eeg_data_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Suppose your cleaned data is in the variable 'preprocessed_data'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg_data_cleaned.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43meeg_data_cleaned\u001b[49m)\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eeg_data_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppose your cleaned data is in the variable 'preprocessed_data'\n",
    "np.save('eeg_data_cleaned.npy', eeg_data_cleaned)\n",
    "np.save('y.npy', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.23; you have 1.21.6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5675\u001b[39m\n\u001b[0;32m      4\u001b[0m channels_to_plot \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m60\u001b[39m]  \u001b[38;5;66;03m# Choose 3 channels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Isha Chaudhari\\python\\tf_env\\lib\\site-packages\\matplotlib\\__init__.py:263\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 263\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\Isha Chaudhari\\python\\tf_env\\lib\\site-packages\\matplotlib\\__init__.py:259\u001b[0m, in \u001b[0;36m_check_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    257\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Matplotlib requires numpy>=1.23; you have 1.21.6"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_idx = 5675\n",
    "channels_to_plot = [60]  # Choose 3 channels\n",
    "\n",
    "for ch in channels_to_plot:\n",
    "    plt.plot(eeg_data_cleaned[sample_idx, ch], label=f'Channel {ch}')\n",
    "plt.title(\"Raw EEG Signal (One Sample)\")\n",
    "plt.xlabel(\"Timepoints\")\n",
    "plt.ylabel(\"μV\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_cleaned = np.load('eeg_data_cleaned.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isha Chaudhari\\AppData\\Local\\Temp\\ipykernel_16084\\2123273693.py:2: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.signal import butter, lfilter, iirnotch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11057, 61, 256) float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, iirnotch\n",
    "\n",
    "# --- Parameters ---\n",
    "sfreq = 256  # Sampling frequency in Hz\n",
    "lowcut = 1.0\n",
    "highcut = 45.0\n",
    "notch_freq = 50.0\n",
    "notch_quality = 30.0\n",
    "order = 4\n",
    "\n",
    "# --- Filter Design ---\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut=1.0, highcut=45.0, fs=256, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def notch_filter(data, fs=256, freq=50.0, quality=30.0):\n",
    "    b, a = iirnotch(freq / (fs / 2), quality)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def baseline_correction(data):\n",
    "    mean = np.mean(data, axis=-1, keepdims=True)\n",
    "    return data - mean\n",
    "\n",
    "# --- Preprocessing Pipeline ---\n",
    "def preprocess_eeg(eeg_data, sfreq=256):\n",
    "    samples, channels, timepoints = eeg_data.shape\n",
    "    preprocessed = np.zeros_like(eeg_data)\n",
    "    for i in range(samples):\n",
    "        for ch in range(channels):\n",
    "            signal = eeg_data[i, ch, :]\n",
    "            # 1. Bandpass filter\n",
    "            filtered = bandpass_filter(signal, lowcut=1.0, highcut=45.0, fs=sfreq, order=4)\n",
    "            # 2. Notch filter\n",
    "            filtered = notch_filter(filtered, fs=sfreq, freq=50.0, quality=30.0)\n",
    "            # 3. Baseline correction\n",
    "            corrected = baseline_correction(filtered)\n",
    "            preprocessed[i, ch, :] = corrected\n",
    "    return preprocessed\n",
    "\n",
    "# Example usage (for a subset due to memory constraints)\n",
    "# eeg_data_cleaned: shape (samples, channels, timepoints)\n",
    "# For demonstration, use a small subset:\n",
    "\n",
    "\n",
    "preprocessed_data = preprocess_eeg(eeg_data_cleaned, sfreq=sfreq)\n",
    "print(preprocessed_data.shape, preprocessed_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X: EEG data, shape (11057, 61, 256)\n",
    "# y: labels, shape (11057,)\n",
    "\n",
    "# First split off the test set (15%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    eeg_data_cleaned, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now split the remaining data into training (70%) and validation (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
    ")\n",
    "# 0.1765 ≈ 0.15 / 0.85, to make validation 15% of original data\n",
    "\n",
    "# Optional: add channel dimension for CNN\n",
    "X_train = X_train[..., None]\n",
    "X_val = X_val[..., None]\n",
    "X_test = X_test[..., None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (11057, 61, 256)\n",
      "Augmented: (7739, 61, 256, 1)\n",
      "Mixup: (7739, 61, 256, 1)\n",
      "Combined: (23217, 61, 256, 1)\n",
      "Labels: (23217,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 3D EEG Augmentation Functions ---\n",
    "\n",
    "def add_gaussian_noise(X, noise_level=0.02):\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "def random_time_shift(X, max_shift=8):\n",
    "    shifted = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        shift = np.random.randint(-max_shift, max_shift)\n",
    "        if shift > 0:\n",
    "            shifted[i, :, shift:] = X[i, :, :-shift]\n",
    "        elif shift < 0:\n",
    "            shifted[i, :, :shift] = X[i, :, -shift:]\n",
    "        else:\n",
    "            shifted[i] = X[i]\n",
    "    return shifted\n",
    "\n",
    "def random_amplitude_scaling(X, scale_range=(0.95, 1.05)):\n",
    "    # X shape: (samples, channels, timepoints, 1)\n",
    "    scales = np.random.uniform(scale_range[0], scale_range[1], (X.shape[0], 1, 1, 1))\n",
    "    return X * scales\n",
    "\n",
    "def channel_reflection(X):\n",
    "    # Reflect channels (reverse channel order)\n",
    "    return X[:, ::-1, :]\n",
    "\n",
    "def channel_masking(X, mask_prob=0.1):\n",
    "    X_masked = X.copy()\n",
    "    for i in range(X.shape[0]):\n",
    "        for ch in range(X.shape[1]):\n",
    "            if np.random.rand() < mask_prob:\n",
    "                X_masked[i, ch, :] = 0\n",
    "    return X_masked\n",
    "\n",
    "def signal_flipping(X):\n",
    "    # Reverse time axis\n",
    "    return X[:, :, ::-1]\n",
    "\n",
    "def mixup(X, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = X.shape[0]\n",
    "    index = np.random.permutation(batch_size)\n",
    "    X_mix = lam * X + (1 - lam) * X[index]\n",
    "    y_mix = lam * y + (1 - lam) * y[index]\n",
    "    return X_mix, y_mix\n",
    "\n",
    "# --- Apply Augmentations ---\n",
    "\n",
    "# Apply augmentations sequentially\n",
    "# Assume you already split your data:\n",
    "# X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Apply augmentations to X_train only\n",
    "X_aug = add_gaussian_noise(X_train)\n",
    "X_aug = random_time_shift(X_aug)\n",
    "X_aug = random_amplitude_scaling(X_aug)\n",
    "X_aug = channel_reflection(X_aug)\n",
    "X_aug = channel_masking(X_aug)\n",
    "X_aug = signal_flipping(X_aug)\n",
    "\n",
    "# Mixup (on training set only)\n",
    "X_mix, y_mix = mixup(X_train, y_train, alpha=0.2)\n",
    "\n",
    "# Combine all data\n",
    "X_train_combined = np.concatenate([X_train, X_aug, X_mix], axis=0)\n",
    "y_train_combined = np.concatenate([y_train, y_train, y_mix], axis=0)\n",
    "\n",
    "\n",
    "print(\"Original:\", eeg_data_cleaned.shape)\n",
    "print(\"Augmented:\", X_aug.shape)\n",
    "print(\"Mixup:\", X_mix.shape)\n",
    "print(\"Combined:\", X_train_combined.shape)\n",
    "print(\"Labels:\", y_train_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 256, 64)           11776     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 128, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 128, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 64, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64, 128)           0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 128)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,153\n",
      "Trainable params: 144,385\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = (256, 61)  # (timesteps, channels)\n",
    "\n",
    "model = models.Sequential([\n",
    "    # CNN block\n",
    "    layers.Conv1D(64, kernel_size=3, activation='elu', padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv1D(128, kernel_size=3, activation='elu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Reshape for LSTM\n",
    "    layers.Reshape((-1, 128)),  # Adjust based on last Conv1D filters\n",
    "\n",
    "    # LSTM block\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=False)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    # Dense layers\n",
    "    layers.Dense(64, activation='elu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 256, 64)           11776     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 128, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 128, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 64, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64, 128)           0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 128)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,153\n",
      "Trainable params: 144,385\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # You can also use 'val_accuracy'\n",
    "    patience=7,                 # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True   # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 461. MiB for an array with shape (7739, 61, 256, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# Set a large max epoch, early stopping will halt earlier if needed\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Isha Chaudhari\\python\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Isha Chaudhari\\python\\tf_env\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 461. MiB for an array with shape (7739, 61, 256, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,                  # Set a large max epoch, early stopping will halt earlier if needed\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1356 - accuracy: 0.9554\n",
      "Test accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step\n",
      "[[ 544   60]\n",
      " [  36 1019]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       604\n",
      "           1       0.94      0.97      0.96      1055\n",
      "\n",
      "    accuracy                           0.94      1659\n",
      "   macro avg       0.94      0.93      0.94      1659\n",
      "weighted avg       0.94      0.94      0.94      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_eeg_cnn_model_with_preprocessing.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
